{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2bb1b2",
   "metadata": {},
   "source": [
    "# Example 6: Functions with integer covariates\n",
    "\n",
    "In this advanced example we show how to solve optimization problems where one or all covariates are integers, including how to modulate the number of random datapoints to improve convergence. We will also show how to configure the data types of the covariates and set the covariate names.\n",
    "\n",
    "We will start by keeping both covariates as integers and will towards the end replace one of the covariates with a continuous variable.\n",
    "\n",
    "\n",
    "## Problem solved in this notebook\n",
    "\n",
    "In this notebook we will illustrate how to use relative improvement by optimizing this known function \n",
    "\n",
    "$$\n",
    "f( x_0 , x_1 ) = \\sin{ \\left( \\frac{x_0 \\pi}{ 10 } \\right)} \\left[ - \\left(6 \\frac{x_1}{ 10 } - 2 \\right)^2 \\sin{ \\left(12 \\frac{x_1}{ 10 } - 4 \\right)} \\right], \\quad x_0 , x_1 \\in \\mathcal{Z}^{+}_{0;10}.\n",
    "$$\n",
    "\n",
    "It is known that the function above has its maximum at $(x_0, x_1)^* = (5,8)$ with a corresponding response of $f(x_0^*, x_1^*) = 4.94913$.\n",
    "\n",
    "We will solve it using the `.auto`-method in and apply conditions on the relative improvement and illustrate their impact on covergence for two different cases\n",
    "\n",
    "1. Using the default settings\n",
    "2. Tweak the rate of random sampling in between Bayesian optimization steps to improve convergence.\n",
    "3. Convert $x_1$ to a continuous variable and solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user greattunes\n",
    "\n",
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from greattunes import CreativeProject\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637ef0a",
   "metadata": {},
   "source": [
    "## Define the function to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the covariates\n",
    "x0scale = 10\n",
    "x1scale = 10\n",
    "\n",
    "# the function to optimize\n",
    "# takes a pandas dataframe as input and returns an array\n",
    "def f(x):\n",
    "    x0, x1 = np.meshgrid(x[\"x0\"].values, x[\"x1\"].values)\n",
    "    x0p = np.round(x0,0)/x0scale\n",
    "    x1p = np.round(x1,0)/x1scale\n",
    "    return np.sin(x0p*np.pi)*(-(6*x1p - 2)**2*np.sin(12*x1p-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7268ef",
   "metadata": {},
   "source": [
    "Plot the function $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for plotting\n",
    "def f_plot(x0vec,x1vec):\n",
    "    xdf = pd.DataFrame({\"x0\": x0vec, \"x1\": x1vec})\n",
    "    x0p, x1p = np.meshgrid(x0vec, x1vec)\n",
    "    return x0p, x1p, f(xdf)\n",
    "    \n",
    "# generate the data to plot\n",
    "x0vec = np.linspace(0,x0scale,200)\n",
    "x1vec = np.linspace(0,x1scale,200)\n",
    "\n",
    "x0p, x1p, output = f_plot(x0vec, x1vec)\n",
    "\n",
    "# Set up a figure twice as tall as it is wide\n",
    "fig = plt.figure(figsize=(12,6)) \n",
    "\n",
    "# First subplot: contour plot \n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "cs = ax.contourf(x0p, x1p, output, cmap=\"jet\")\n",
    "ax.set_xlabel(\"$x_0$\")\n",
    "ax.set_ylabel(\"$x_1$\")\n",
    "cbar = fig.colorbar(cs)\n",
    "\n",
    "\n",
    "# Second subplot: surface plot\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.view_init(elev=20., azim=19)\n",
    "ax.plot_surface(x0p, x1p, output, rstride=1, cstride=1,linewidth=1, antialiased=True, shade=True, cmap=\"jet\")\n",
    "ax.set_xlabel(\"$x_0$\")\n",
    "ax.set_ylabel(\"$x_1$\")\n",
    "ax.set_zlabel(\"Response\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6364345",
   "metadata": {},
   "source": [
    "Define the covariate variables and name them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f33282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of interest\n",
    "x0_init = 2\n",
    "x1_init = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34af038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariate names\n",
    "x0_name = \"x0\"\n",
    "x1_name = \"x1\"\n",
    "\n",
    "# set data type for covariates. For integer covariates use type int\n",
    "x0_type = int\n",
    "x1_type = int\n",
    "\n",
    "# create the covariate-defining data structure as a named nested dicts\n",
    "covars2d = {\n",
    "    x0_name: {\n",
    "        \"guess\": x0_init,\n",
    "        \"min\": 0,\n",
    "        \"max\": x0scale,\n",
    "        \"type\": int,\n",
    "    },\n",
    "    x1_name: {\n",
    "        \"guess\": x1_init,\n",
    "        \"min\": 0,\n",
    "        \"max\": x1scale,\n",
    "        \"type\": int,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b0b0c",
   "metadata": {},
   "source": [
    "## 1: Solve the problem with standard settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize class instance\n",
    "cc = CreativeProject(covars=covars2d)\n",
    "\n",
    "# number of iterations\n",
    "max_iter = 90\n",
    "\n",
    "# run the auto-method\n",
    "cc.auto(response_samp_func=f, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24244153",
   "metadata": {},
   "source": [
    "Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run current_best method\n",
    "cc.current_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate the convergence\n",
    "cc.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot best result vs iterations\n",
    "cc.plot_best_objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904529b",
   "metadata": {},
   "source": [
    "## 2: Improve convergence by increasing random sampling\n",
    "\n",
    "Here we will start by running first 6 random samples using latin hypercube sampling. We set this via the`num_initiaL_random` argument. Secondly we will also increase the cadence by which random samples will be interdispersed among the Bayesian steps by setting `random_step_candence` to 5 instead of the 10 used by default. Beware that it is also possible to change between different sampling methods (current fully random and latin hypercube sampling methods are available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe879f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize class instance\n",
    "cc2 = CreativeProject(covars=covars2d, random_step_cadence=5, num_initial_random=6)\n",
    "\n",
    "# number of iterations\n",
    "max_iter = 90\n",
    "\n",
    "# run the auto-method\n",
    "cc2.auto(response_samp_func=f, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25164400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run current_best method\n",
    "cc2.current_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot convergence\n",
    "cc2.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evolution of best result of objective function\n",
    "cc2.plot_best_objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5454ab2",
   "metadata": {},
   "source": [
    "## 3: Converting covariate $x_1$ to a continuous variable\n",
    "\n",
    "For illustration purposes, we in this example convert the covariate $x_1$ to a continuous variable by explicitly setting it as a continuous variable. The response function is also updated so it processes continuous values for $x_1$.\n",
    "\n",
    "By making this change, we are no longer solving the same problem as the one in the two cases above. Nonetheless the changes illustrate that convergence is typically achieved faster if not all covariates are integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54605e",
   "metadata": {},
   "source": [
    "### Defining covariates\n",
    "Covariates can either be defined via a list of tuples (see Examples 1 - 5) or via a nested dict as show earlier in this example. In the former case, the data type of the covariate is inferred from the data provided to define the covariates (a single float data type in a tuple will cast it as type float).\n",
    "\n",
    "For completeness we show below how to define the same covariates (one an integer, the other a continuous) using both approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of interest\n",
    "x0_init = 2\n",
    "x1_init = 6.0\n",
    "\n",
    "# using list of tuples\n",
    "# in this case the covariates will be assigned names \"covar0\", \"covar1\"\n",
    "# covars2d_tuples = [(x0_init, 0 , x0scale), (x1_init, 0, x1scale)]\n",
    "\n",
    "# create the covariate-defining data structure as a named nested dicts\n",
    "# with this approach the covariates can be named directly\n",
    "covars2d_dict = {\n",
    "    x0_name: {\n",
    "        \"guess\": x0_init,\n",
    "        \"min\": 0,\n",
    "        \"max\": x0scale,\n",
    "        \"type\": int,\n",
    "    },\n",
    "    x1_name: {\n",
    "        \"guess\": x1_init,\n",
    "        \"min\": 0,\n",
    "        \"max\": x1scale,\n",
    "        \"type\": float,  # change data type to continuous\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af546846",
   "metadata": {},
   "source": [
    "Update the response function so it accepts $x_1$ as a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to optimize\n",
    "# takes a pandas dataframe as input and returns an array\n",
    "def f_cont(x):\n",
    "    x0, x1 = np.meshgrid(x[\"x0\"].values, x[\"x1\"].values)\n",
    "    x0p = np.round(x0,0)/x0scale\n",
    "    x1p = x1/x1scale  # updated here\n",
    "    return np.sin(x0p*np.pi)*(-(6*x1p - 2)**2*np.sin(12*x1p-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for plotting\n",
    "def f_cont_plot(x0vec,x1vec):\n",
    "    xdf = pd.DataFrame({\"x0\": x0vec, \"x1\": x1vec})\n",
    "    x0p, x1p = np.meshgrid(x0vec, x1vec)\n",
    "    return x0p, x1p, f_cont(xdf)\n",
    "    \n",
    "# generate the data to plot\n",
    "x0vec = np.linspace(0,x0scale,200)\n",
    "x1vec = np.linspace(0,x1scale,200)\n",
    "\n",
    "x0p, x1p, output = f_cont_plot(x0vec, x1vec)\n",
    "\n",
    "# Set up a figure twice as tall as it is wide\n",
    "fig = plt.figure(figsize=(12,6)) \n",
    "\n",
    "# First subplot: contour plot \n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "cs = ax.contourf(x0p, x1p, output, cmap=\"jet\")\n",
    "ax.set_xlabel(\"$x_0$\")\n",
    "ax.set_ylabel(\"$x_1$\")\n",
    "cbar = fig.colorbar(cs)\n",
    "\n",
    "\n",
    "# Second subplot: surface plot\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.view_init(elev=20., azim=19)\n",
    "ax.plot_surface(x0p, x1p, output, rstride=1, cstride=1,linewidth=1, antialiased=True, shade=True, cmap=\"jet\")\n",
    "ax.set_xlabel(\"$x_0$\")\n",
    "ax.set_ylabel(\"$x_1$\")\n",
    "ax.set_zlabel(\"Response\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc59f26",
   "metadata": {},
   "source": [
    "### Solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1195fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize class instance\n",
    "cc3 = CreativeProject(covars=covars2d_dict)\n",
    "\n",
    "# number of iterations\n",
    "max_iter = 90\n",
    "\n",
    "# run the auto-method\n",
    "cc3.auto(response_samp_func=f_cont, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9de080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run current_best method\n",
    "cc3.current_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot convergence\n",
    "cc3.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evolution of best result of objective function\n",
    "cc3.plot_best_objective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545097c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
